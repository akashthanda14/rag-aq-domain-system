# RAG System Configuration
# CSE435 Project

# Model Configuration
embeddings:
  model_name: "sentence-transformers/all-MiniLM-L6-v2"
  embedding_dim: 384
  device: "cpu"  # Options: cpu, cuda, mps
  batch_size: 32

llm:
  model_name: "gpt-3.5-turbo"
  temperature: 0.7
  max_tokens: 500
  include_citations: true

# Vector Database Configuration
vector_db:
  type: "faiss"  # Options: faiss, chromadb, pinecone
  path: "data/vector_store"
  similarity_metric: "cosine"  # Options: cosine, euclidean, dot

# Document Ingestion Configuration
ingestion:
  data_dir: "data/raw"
  chunk_size: 1000
  chunk_overlap: 200
  supported_formats:
    - .txt
    - .pdf
    - .docx
    - .md
    - .html

# Retrieval Configuration
retrieval:
  top_k: 5
  use_reranking: false
  rerank_top_k: 20
  use_hybrid_search: false
  hybrid_alpha: 0.5  # Weight for dense retrieval

# System Configuration
system:
  log_level: "INFO"
  log_file: null  # Set to path for file logging
  cache_embeddings: true
  max_cache_size: 10000

# API Configuration (values from environment variables)
api_keys:
  openai: ${OPENAI_API_KEY}
  anthropic: ${ANTHROPIC_API_KEY}
  pinecone: ${PINECONE_API_KEY}
  huggingface: ${HUGGINGFACE_API_KEY}
